# ğŸº Projeto de IngestÃ£o e Modelagem de Dados - Open Brewery DB

Este projeto realiza a ingestÃ£o de dados da API pÃºblica [Open Brewery DB](https://www.openbrewerydb.org/), salvando os dados brutos em PostgreSQL e posteriormente no catÃ¡logo do Databricks, seguindo a arquitetura Medallion (camadas bronze, silver e gold). O pipeline estÃ¡ versionado no GitHub e executado por Jobs no Databricks.

---

## âš™ï¸ Etapa 1 - Infraestrutura local com Docker Compose

Utilizamos um `docker-compose.yml` para levantar dois serviÃ§os:

- **PostgreSQL**: para persistÃªncia inicial dos dados brutos
- **Jupyter Notebook**: ambiente de desenvolvimento em Python

### ğŸ”§ Como subir:

```bash
docker compose up -d
```

---

## ğŸ”„ Etapa 2 â€“ IngestÃ£o com Python + Airbyte

Inicialmente, a API [Open Brewery DB](https://www.openbrewerydb.org/) foi consumida usando Python e armazenada localmente em um banco **PostgreSQL** via Docker, com os dados brutos salvos como `jsonb`.

Posteriormente, utilizamos o **Airbyte** para realizar a ingestÃ£o automÃ¡tica dos dados do PostgreSQL para o **catÃ¡logo do Databricks** (Unity Catalog).

### ğŸ”§ ConfiguraÃ§Ã£o do Airbyte:

- **Fonte (source):** PostgreSQL (Docker local)
- **Destino (destination):** Databricks Delta Lake (Unity Catalog)
- **Tabela destino:** `projto_ambev.public.raw_breweries`

Dessa forma, a ingestÃ£o Ã© automatizada e mantida atualizada de forma confiÃ¡vel, servindo como base para o restante do pipeline (bronze â†’ silver â†’ gold).

---

## ğŸ§± Etapa 3 - Arquitetura Medallion (Bronze, Silver, Gold)

### ğŸ”¹ Bronze

- PersistÃªncia do JSON bruto vindo do PostgreSQL
- Tabela: `projto_ambev.bronze.breweries_json`

### ğŸ”¹ Silver

- ConversÃ£o do campo `raw_data` (string JSON) para `STRUCT` usando `from_json`
- ExtraÃ§Ã£o dos principais campos: `id`, `name`, `brewery_type`, `city`, `state`, `latitude`, etc.
- Tabela: `projto_ambev.silver.breweries`

### ğŸ”¹ Gold

AgregaÃ§Ãµes analÃ­ticas:

- Total de cervejarias por estado â†’ `gold.total_por_estado`
- Total por tipo de cervejaria â†’ `gold.total_por_tipo`
- Top 10 cidades com mais cervejarias â†’ `gold.top10_cidades`

---

## ğŸ”„ Etapa 4 - OrquestraÃ§Ã£o com Databricks Jobs

Criamos um Job com mÃºltiplas tasks no Databricks que executa:

1. Notebook Bronze â†’ Silver
2. Notebook Silver â†’ Gold

TambÃ©m Ã© possÃ­vel configurar agendamento e alertas via interface grÃ¡fica.

---

## ğŸ—‚ï¸ Estrutura final no Databricks

```
projto_ambev/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ raw_breweries
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ breweries_json
â”œâ”€â”€ silver/
â”‚   â””â”€â”€ breweries
â””â”€â”€ gold/
    â”œâ”€â”€ total_por_estado
    â”œâ”€â”€ total_por_tipo
    â””â”€â”€ top10_cidades
```

---

## ğŸ’» Tecnologias utilizadas

- Python 3
- Docker + Docker Compose
- PostgreSQL
- Jupyter Notebook
- Spark (Databricks)
- Delta Lake
- Unity Catalog
- GitHub
- Airbyte
- Databricks Jobs

---
---

## ğŸ“’ Notebooks do Projeto

Este repositÃ³rio tambÃ©m inclui notebooks utilizados nas etapas do pipeline de dados:

### ğŸ”¹ `Extraindo_dados_brutos.ipynb`
ğŸ“¥ Executado localmente no Jupyter Notebook.  
ResponsÃ¡vel por extrair dados da API [Open Brewery DB](https://www.openbrewerydb.org/) e inserir os registros no banco **PostgreSQL** que estÃ¡ rodando em um container Docker.

---

### ğŸ”¹ `1_bronze_copia_dados.ipynb`
ğŸ“¦ Notebook executado no **Databricks**.  
LÃª os dados do PostgreSQL e os salva no formato Delta Lake, compondo a camada **Bronze**, onde os dados sÃ£o mantidos em sua forma bruta.

---

### ğŸ”¹ `2_silver_normalizar_dados.ipynb`
ğŸ§¹ TambÃ©m executado no **Databricks**.  
Transforma os dados brutos da Bronze, usando funÃ§Ãµes como `from_json` e `selectExpr`, para extrair e normalizar os principais campos, criando a camada **Silver**.

---

### ğŸ”¹ `3_gold_dados_mensurados.ipynb`
ğŸ“Š Notebook final executado no **Databricks**.  
Agrega os dados normalizados da camada Silver em mÃ©tricas e indicadores analÃ­ticos, compondo a camada **Gold**, que serve de base para dashboards e consumo analÃ­tico.

---

## ğŸ‘¨â€ğŸ’» Autor

Rafael Carlos dos Santos  
Engenheiro de Dados | [LinkedIn](https://www.linkedin.com/in/rafaelcarlossantos/)